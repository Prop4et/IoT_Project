{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from influxdb_client import InfluxDBClient\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_temp = []\n",
    "rmse_hum = []\n",
    "rmse_gas = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we go from minute to minute\n",
    "fd =  open('../../server/config.json', 'r')\n",
    "config = json.load(fd)\n",
    "fd.close()\n",
    "minutes = 30\n",
    "for i in range(0, 30):\n",
    "    query_temp = 'from(bucket:\"temp\")' \\\n",
    "            ' |> range(start:2022-06-14T12:'+str(minutes+i)+':00Z, stop:2022-06-14T15:'+str(minutes+i)+':00Z)'\\\n",
    "            ' |> filter(fn: (r) => r._measurement == \"val\" and r._field == \"value\")'\n",
    "    client =  InfluxDBClient(url='http://'+config[\"influx\"][\"remotehost\"]+':'+config[\"influx\"][\"port\"], token=config[\"influx\"][\"token\"], org=config[\"influx\"][\"org\"], debug=False)\n",
    "    write_api = client.write_api(write_options=SYNCHRONOUS)\n",
    "    query_api = client.query_api()  \n",
    "    result = query_api.query_data_frame(query_temp)\n",
    "    df = result.drop(columns=['result', 'table', '_start', '_stop', '_field', '_measurement'])\n",
    "    df_temp = df.copy()\n",
    "    df_temp = df_temp.loc[df_temp['sensor'] == '0']\n",
    "    df_temp = df_temp.drop(columns=['lat', 'lon', 'sensor'])\n",
    "    df_temp = df_temp.rename(columns = {'_time': 'Time', '_value': 'y'})\n",
    "    df_temp['Time'] = df_temp['Time'].dt.strftime('%d-%m-%Y %H:%M:%S')\n",
    "    df_temp\n",
    "    l = len(df_temp.values)\n",
    "    splitpoint = int(l*0.90)\n",
    "    train = df_temp['y'][:splitpoint]\n",
    "    test = df_temp['y'][splitpoint:]\n",
    "    model = ARIMA(train, order=(1,1,1)) \n",
    "    model_fit = model.fit()\n",
    "    predictions = model_fit.forecast(len(test.index))\n",
    "    rmse_temp.append(math.sqrt(mean_squared_error(test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 30):\n",
    "    query_hum = 'from(bucket:\"hum\")' \\\n",
    "            ' |> range(start:2022-06-14T12:'+str(minutes+i)+':00Z, stop:2022-06-14T15:'+str(minutes+i)+':00Z)'\\\n",
    "            ' |> filter(fn: (r) => r._measurement == \"val\" and r._field == \"value\")'\n",
    "    client =  InfluxDBClient(url='http://'+config[\"influx\"][\"remotehost\"]+':'+config[\"influx\"][\"port\"], token=config[\"influx\"][\"token\"], org=config[\"influx\"][\"org\"], debug=False)\n",
    "    write_api = client.write_api(write_options=SYNCHRONOUS)\n",
    "    query_api = client.query_api()  \n",
    "    result = query_api.query_data_frame(query_hum)\n",
    "    df = result.drop(columns=['result', 'table', '_start', '_stop', '_field', '_measurement'])\n",
    "    df_hum = df.copy()\n",
    "    df_hum = df_hum.loc[df_hum['sensor'] == '0']\n",
    "    df_hum = df_hum.drop(columns=['lat', 'lon', 'sensor'])\n",
    "    df_hum = df_hum.rename(columns = {'_time': 'Time', '_value': 'y'})\n",
    "    df_hum['Time'] = df_hum['Time'].dt.strftime('%d-%m-%Y %H:%M:%S')\n",
    "    df_hum\n",
    "    l = len(df_hum.values)\n",
    "    splitpoint = int(l*0.90)\n",
    "    train = df_hum['y'][:splitpoint]\n",
    "    test = df_hum['y'][splitpoint:]\n",
    "    model = ARIMA(train, order=(1,1,1)) \n",
    "    model_fit = model.fit()\n",
    "    predictions = model_fit.forecast(len(test.index))\n",
    "    rmse_hum.append(math.sqrt(mean_squared_error(test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\franc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 30):\n",
    "    query_gas = 'from(bucket:\"smoke\")' \\\n",
    "            ' |> range(start:2022-06-14T12:'+str(minutes+i)+':00Z, stop:2022-06-14T15:'+str(minutes+i)+':00Z)'\\\n",
    "            ' |> filter(fn: (r) => r._measurement == \"val\" and r._field == \"value\")'\n",
    "    client =  InfluxDBClient(url='http://'+config[\"influx\"][\"remotehost\"]+':'+config[\"influx\"][\"port\"], token=config[\"influx\"][\"token\"], org=config[\"influx\"][\"org\"], debug=False)\n",
    "    write_api = client.write_api(write_options=SYNCHRONOUS)\n",
    "    query_api = client.query_api()  \n",
    "    result = query_api.query_data_frame(query_gas)\n",
    "    df = result.drop(columns=['result', 'table', '_start', '_stop', '_field', '_measurement'])\n",
    "    df_gas = df.copy()\n",
    "    df_gas = df_gas.loc[df_gas['sensor'] == '0']\n",
    "    df_gas = df_gas.drop(columns=['lat', 'lon', 'sensor'])\n",
    "    df_gas = df_gas.rename(columns = {'_time': 'Time', '_value': 'y'})\n",
    "    df_gas['Time'] = df_gas['Time'].dt.strftime('%d-%m-%Y %H:%M:%S')\n",
    "    df_gas\n",
    "    l = len(df_gas.values)\n",
    "    splitpoint = int(l*0.90)\n",
    "    train = df_gas['y'][:splitpoint]\n",
    "    test = df_gas['y'][splitpoint:]\n",
    "    model = ARIMA(train, order=(1,1,1)) \n",
    "    model_fit = model.fit()\n",
    "    predictions = model_fit.forecast(len(test.index))\n",
    "    rmse_gas.append(math.sqrt(mean_squared_error(test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = ['Temp', 'Hum', 'Gas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean for Temp 0.0681 conf: 0.000721 high bound: 0.0689 low bound: 0.0674\n",
      "Mean for Hum 0.22 conf: 0.00711 high bound: 0.227 low bound: 0.213\n",
      "Mean for Gas 0.0366 conf: 0.000432 high bound: 0.037 low bound: 0.0362\n"
     ]
    }
   ],
   "source": [
    "df_results = pd.DataFrame.from_dict({'Temp': rmse_temp, 'Hum':rmse_hum, 'Gas':rmse_gas})\n",
    "described = df_results.describe()\n",
    "for s in series:\n",
    "    mean = described.loc['mean'][s]\n",
    "    conf = described.loc['std'][s]/math.sqrt(described.loc['count'][s])\n",
    "    print('Mean for ' + s +' {:.3g}'.format(mean) + ' conf: {:.3g}'.format(conf) + ' high bound: {:.3g}'.format(mean+conf) + ' low bound: {:.3g}'.format(mean-conf))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6e91d7251fb344e996def3e92284d431619133ca817cffa03ab54840799a3500"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
